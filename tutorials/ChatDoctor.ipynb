{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatDoctor (LLM App)\n",
    "\n",
    "ChatDoctor is an LLLM chatbot that can assist patients providing medical answers. Let's see how we can test and evaluate this LLM App with [Lynxius](https://www.lynxius.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To set up [Lynxius](https://www.lynxius.ai/) you only need to import the `LYNXIUS_API_KEY` and install [Lynxius](https://www.lynxius.ai/) library with `pip install lynxius`. In this tutorial we are going to run [Lynxius](https://www.lynxius.ai/) directly from it's source code instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Enter your Lynxius API key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# First, we have to setup Lynxius API key\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "if not (lynxius_api_key := os.getenv(\"LYNXIUS_API_KEY\")):\n",
    "    lynxius_api_key = getpass(\"ğŸ”‘ Enter your Lynxius API key: \")\n",
    "\n",
    "os.environ[\"LYNXIUS_API_KEY\"] = lynxius_api_key\n",
    "os.environ[\"LYNXIUS_BASE_URL\"] = \"https://REQUEST-THE-ENDPOINT-TO-GET-ACCESS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these [Postman](https://www.postman.com/) collections to upload to your platform the datasets used in this notebook:\n",
    "\n",
    "1. [Lynxius ChatDoctor Project (1/3)](./data/postman/Lynxius_ChatDoctor_Project_1_of_3.postman_collection.json) to upload **Dataset_v1**\n",
    "2. [Lynxius ChatDoctor Project (2/3)](./data/postman/Lynxius_ChatDoctor_Project_2_of_3.postman_collection.json) to upload **Dataset_v2**\n",
    "3. [Lynxius ChatDoctor Project (3/3)](./data/postman/Lynxius_ChatDoctor_Project_3_of_3.postman_collection.json) to upload **Dataset_v2-labeled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate ChatDoctor_v1 against our Dataset_v1\n",
    "\n",
    "There is already **Dataset_v1** stored in your platform that containes some question and ground-truth answer pairs. Let's download it with the `get_dataset_details()` function.\n",
    "\n",
    "We can now evaluate your **ChatDoctor_v1** LLM application by comparing its outputs to **Dataset_v1** queries with the respective ground-truth reference answers provided in **Dataset_v1**. In this notebook we are going to use `BertScore` and `AnswerCorrectness` metrics for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I prevent the flu?\n",
      "What are the early signs of diabetes?\n",
      "How do I know if I have a food allergy?\n",
      "What should I do if I get a sunburn?\n"
     ]
    }
   ],
   "source": [
    "from lynxius.client import LynxiusClient\n",
    "\n",
    "client = LynxiusClient()\n",
    "\n",
    "# Downloading Dataset_v1 from Lynxius platform\n",
    "dataset_details = client.get_dataset_details(dataset_id=\"DATASET_V1_UUID\")\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    print(entry.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fbcdd27d-a973-4b12-a7dc-9ece1e222cb0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets_utils import chatdoctor_v1\n",
    "\n",
    "from lynxius.evals.bert_score import BertScore\n",
    "from lynxius.evals.answer_correctness import AnswerCorrectness\n",
    "\n",
    "label = \"PR #111\"\n",
    "tags = [\"GPT-4\", \"chatdoctor_v1\", \"Dataset_v1\"]\n",
    "bert_score = BertScore(label=label, tags=tags, level=\"sentence\", presence_threshold=0.65)\n",
    "answer_correctness = AnswerCorrectness(label=label, tags=tags)\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    actual_output = chatdoctor_v1(entry.query)\n",
    "    \n",
    "    bert_score.add_trace(reference=entry.reference, output=actual_output)\n",
    "    answer_correctness.add_trace(query=entry.query, reference=entry.reference, output=actual_output)\n",
    "\n",
    "# Run!\n",
    "client.evaluate(bert_score)\n",
    "client.evaluate(answer_correctness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ğŸš€ğŸš€ It looks like the evaluations scored pretty well! **ChatDoctor_v1** can be deployed to production! ğŸš€ğŸš€ğŸš€\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/chatdoctorv1_datasetv1.png\" alt=\"chatdoctorv1_datasetv1\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Monitoring\n",
    "\n",
    "âš ï¸âš ï¸âš ï¸ From the [Lynxius](https://www.lynxius.ai/) you can monitor **ChatDoctor_v1** performance and spot quickly that its performance is decreasing over the weeks. It seems your users are asking queries that your **ChatDoctor_v1** cannot reply with a great level of correctness. âš ï¸âš ï¸âš ï¸\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/chatdoctorv1_monitor.png\" alt=\"chatdoctorv1_monitor.png\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Data Capturing\n",
    "\n",
    "Thankfully [Lynxius](https://www.lynxius.ai/) automatically collects your users' queries and empowers you to efficiently debug edge cases. In this case **Dataset_v2** has been automatically collected.\n",
    "\n",
    "It seems like your users are asking about the **symptoms** related to specific conditions and your chatbot is not able to provide correct answers to these new kind of queries.\n",
    "\n",
    "Your Subject Matter Expert (SMEs), like medical doctors ğŸ‘©â€âš•ï¸ğŸ‘¨â€âš•ï¸, can use [Lynxius](https://www.lynxius.ai/) UI to quickly spot this edge case and they can annotate the new queries with high quality reference data âœ…\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/datasetv2_spotted_symptoms.png\" alt=\"datasetv2_spotted_symptoms\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate ChatDoctor_v1 against our Dataset_v2-labeled\n",
    "\n",
    "Once your SMEs correctely annotated your new data, you can evaluate again **ChatDoctor_v1** to see the real performance against **Dataset_v2-labeled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I prevent the flu?\n",
      "What are the early signs of diabetes?\n",
      "How do I know if I have a food allergy?\n",
      "What should I do if I get a sunburn?\n",
      "What are the symptoms of a migraine headache?\n",
      "What are the symptoms of the common cold?\n",
      "What are the symptoms of a urinary tract infection (UTI)?\n"
     ]
    }
   ],
   "source": [
    "# Downloading Dataset_v2 from Lynxius platform\n",
    "dataset_details = client.get_dataset_details(dataset_id=\"DATASET_V2_LABELED_UUID\")\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    print(entry.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7097779c-a2af-4a14-bfd0-9a534db466b3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets_utils import chatdoctor_v1\n",
    "\n",
    "from lynxius.evals.bert_score import BertScore\n",
    "from lynxius.evals.answer_correctness import AnswerCorrectness\n",
    "\n",
    "label = \"PR #222\"\n",
    "tags = [\"GPT-4\", \"chatdoctor_v1\", \"Dataset_v2-labeled\"]\n",
    "bert_score = BertScore(label=label, tags=tags, level=\"sentence\", presence_threshold=0.65)\n",
    "answer_correctness = AnswerCorrectness(label=label, tags=tags)\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    actual_output = chatdoctor_v1(entry.query)\n",
    "    \n",
    "    bert_score.add_trace(reference=entry.reference, output=actual_output)\n",
    "    answer_correctness.add_trace(query=entry.query, reference=entry.reference, output=actual_output)\n",
    "\n",
    "# Run!\n",
    "client.evaluate(bert_score)\n",
    "client.evaluate(answer_correctness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âŒâŒâŒ It looks like the evaluations scores were not acceptable âŒâŒâŒ\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/chatdoctorv1_datasetv2labeled.png\" alt=\"chatdoctorv1_datasetv2labeled\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to build ChatDoctor_v2\n",
    "\n",
    "ğŸ”§ğŸ”¨ğŸ”© **ChatDoctor_v1** clearly cannot handle the new edge case and the team needs to work hard on the new**ChatDoctor_v2**. ğŸ”§ğŸ”¨ğŸ”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate ChatDoctor_v2 against our Dataset_v2-lebeled\n",
    "\n",
    "Once ***ChatDoctor_v2*** is ready we can test it agains the dataset labeled by your SMEs, **Dataset_v2-lebeled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I prevent the flu?\n",
      "What are the early signs of diabetes?\n",
      "How do I know if I have a food allergy?\n",
      "What should I do if I get a sunburn?\n",
      "What are the symptoms of a migraine headache?\n",
      "What are the symptoms of the common cold?\n",
      "What are the symptoms of a urinary tract infection (UTI)?\n"
     ]
    }
   ],
   "source": [
    "# Downloading Dataset_v2 from Lynxius platform\n",
    "dataset_details = client.get_dataset_details(dataset_id=\"DATASET_V2_LABELED_UUID\")\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    print(entry.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f934d5e0-fe25-4884-a51e-79edffd786d0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets_utils import chatdoctor_v2\n",
    "\n",
    "from lynxius.evals.bert_score import BertScore\n",
    "from lynxius.evals.answer_correctness import AnswerCorrectness\n",
    "\n",
    "label = \"PR #333\"\n",
    "tags = [\"GPT-4\", \"chatdoctor_v2\", \"Dataset_v2-labeled\"]\n",
    "bert_score = BertScore(label=label, tags=tags, level=\"sentence\", presence_threshold=0.65)\n",
    "answer_correctness = AnswerCorrectness(label=label, tags=tags)\n",
    "\n",
    "for entry in dataset_details.entries:\n",
    "    actual_output = chatdoctor_v2(entry.query)\n",
    "\n",
    "    bert_score.add_trace(reference=entry.reference, output=actual_output)\n",
    "    answer_correctness.add_trace(query=entry.query, reference=entry.reference, output=actual_output)\n",
    "\n",
    "# Run!\n",
    "client.evaluate(bert_score)\n",
    "client.evaluate(answer_correctness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ğŸš€ğŸš€ Yess!!! It looks like the evaluations scored well! ğŸš€ğŸš€ğŸš€\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/chatdoctorv2_datasetv2labeled.png\" alt=\"chatdoctorv2_datasetv2labeled\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ğŸš€ğŸš€ We can also see that **ChatDoctor_v2** clearly outperforms **ChatDoctor_v1** ğŸš€ğŸš€ğŸš€\n",
    "\n",
    "<img src=\"https://github-public-assets.s3.us-west-1.amazonaws.com/chatdoctorv2_monitor.png\" alt=\"chatdoctorv2_monitor\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Considerations\n",
    "\n",
    "[Lynxius](https://www.lynxius.ai/) platform helped the team to evaluate their LLM Apps and decide when they were ready to deploy to production âœ…âœ…âœ…. It also empowered the team to discover production issues fast âœ…âœ…âœ… and collect important end user input queries to further improve their product âœ…âœ…âœ…"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
